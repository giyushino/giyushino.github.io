<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>First Blog Post</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,500;1,400;1,500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../styles.css">
    <link id="hljs-theme" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <!-- MathJax for LaTeX support -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>
<body>
    <header>
        <nav>
            <div class="logo"><a href="post.html" style="text-decoration: none; color: inherit;">BLOG</a></div>
            <ul class="nav-links">
                <li><a href="../index.html">ABOUT</a></li>
            </ul>
            <button class="theme-toggle" aria-label="Toggle dark mode">
                <span class="theme-icon"></span>
            </button>
        </nav>
    </header>

    <main>
        <div class="container blog-post">
            <article class="about-content">
                <h1>Rejection Sampling GRPO</h1>
                <p>Group relative policy optimization, or GRPO, is one of the most promising reinforcement learning algorithms to emerge recently. Unlike DPO<sup class="sidenote-ref">1</sup><span class="sidenote" data-note-number="1">Direct Policy Optimization</span>, which requires preference pairs, or PPO<sup class="sidenote-ref">2</sup><span class="sidenote" data-note-number="2">Preference Policy Optimization</span>, which needs a trained reward model, GRPO uses the language model itself to score outputs. This self-contrained approach simplifies the training process while still yielding huge performance gains</p>
                <p>Although GRPO already shows strong results, is there anything we can do to improve it?</p>
                <h2>How does GRPO work? </h2>

                <img src="#" alt="Diagram of GRPO" style="max-width: 100%; height: auto; margin: 1.5rem 0; border-radius: 6px; clip-path: inset(2px);">
                <p>Before we start training, we must define a reward function, which maps each completion to an integer score. A very standard reward function rewards correct completions with 1 and incorrect ones with 0. There are even cases where unfinished or improperly formatted completions get a negative score.
                <pre><code>def compute_reward(x, y):
    """Compute the gradient of a function."""
    dx = (y[1:] - y[:-1]) / (x[1:] - x[:-1])
    return dx</code></pre>
                For each step during training, the dataloader samples $M$ unique prompts and generates $K$ completions for each one.</p>

                <p>$$\int_{-\infty}^{\infty} e^{-x^2} dx = \sqrt{\pi}$$</p>

                <h2>Main Content</h2>

                <p>Add your main content here.<sup class="sidenote-ref">2</sup><span class="sidenote" data-note-number="2">Here's another side note example. These are great for adding references, clarifications, or additional context without interrupting the main flow.</span> You can use inline math like $\alpha + \beta = \gamma$ or more complex expressions such as $\frac{d}{dx}f(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}$.</p>

                <p>For display equations, use double dollar signs:</p>

                <p>$$\sum_{i=1}^{n} i = \frac{n(n+1)}{2}$$</p>

                <h2>Conclusion</h2>

                <p>Wrap up your thoughts here.</p>
            </article>
        </div>
    </main>
    <script>
        const toggle = document.querySelector('.theme-toggle');
        const icon = toggle.querySelector('.theme-icon');
        const hljsTheme = document.getElementById('hljs-theme');

        function setTheme(dark) {
            document.documentElement.setAttribute('data-theme', dark ? 'dark' : 'light');
            icon.textContent = dark ? 'light' : 'dark';
            hljsTheme.href = dark
                ? 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css'
                : 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css';
            localStorage.setItem('theme', dark ? 'dark' : 'light');
        }

        const saved = localStorage.getItem('theme');
        const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
        setTheme(saved ? saved === 'dark' : prefersDark);
        hljs.highlightAll();

        toggle.addEventListener('click', () => {
            const isDark = document.documentElement.getAttribute('data-theme') === 'dark';
            setTheme(!isDark);
        });
    </script>
</body>
</html>

